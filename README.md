
# Group 6 | Accessibility Project

## Problem

One of the issues deaf and hard of hearing individuals might face is the difficulty with accessing fluent communication within the areas around them. Current tools only translate sign language word to word, which more often than not can result in clumsy or out-of-context-text. The necessity of developing a system powered by AI that comprehends gestures and translates them into natural and conversational speech or text is evident.

## Proposed Solution

We have decided to develop an artificial intelligence solution where the sign language signals can be translated to readable text and speech in real-time. It is able to interpret hand signals through computer vision and use a large language model to rebuild those cues into coherent, natural, grammatically correct and human-like sentences.

# Technologies Used

## Backend

* FastAPI

## AI

* YOLO - Computer Vision Model
* Gemma LLM

## Frontend

* React
* Tailwind CSS - Styling
* Next.js
