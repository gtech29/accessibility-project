import ollama

def process_llm(word: str):

    text = word

    abbreviations = {
    "hbu": "how about you",
    "hru": "how are you",
    "ily": "I love you",
    "xoxo": "hugs and kisses",
    "ngl": "not gonna lie",
    "nb": "no biggie",
    "tbh": "to be honest",
    "omg": "oh my god",
    "idk": "I don't know",
    "lol": "laugh out loud",
    "brb": "be right back",
    "gtg": "got to go",
    "imo": "in my opinion",
    "bc": "because",
    "rn": "right now",
    "rip": "rest in peace"
    }

    emotionList = {"Happy", "Sad", "Angry","Excited"}

    sentence = ""
    emotion = ""
    results = {"Sentence":"", "Emotion": ""}



#______________________________AI generated by chatGPT____________________________________
    def greedy_match(text, abbreviations):
        text_u = text
        text_cmp = text.upper()

        # normalize abbreviation keys to uppercase once
        abbr_map = {k.upper(): v for k, v in abbreviations.items()}
        abbr_keys = sorted(abbr_map.keys(), key=len, reverse=True)

        result = ""   # now a string
        buffer = ""   # now a string
        i = 0

        while i < len(text_cmp):
            matched = False

            # try match an abbreviation at position i
            for abbr in abbr_keys:
                if text_cmp.startswith(abbr, i):
                    # flush buffered normal word first
                    if buffer:
                        result += buffer
                        buffer = ""

                    result += abbr_map[abbr]  # expanded abbreviation
                    i += len(abbr)
                    matched = True
                    break

            if not matched:
                ch = text_u[i]        # output char (original case)
                ch_cmp = text_cmp[i]  # matching char (uppercase)

                if ch_cmp.isalpha():
                    buffer += ch
                else:
                    if buffer:
                        result += buffer
                        buffer = ""
                    result += ch

                i += 1

        # flush leftover word
        if buffer:
            result += buffer

        return result
#________________________________________AI generated ends______________________________________
    
    context = "a girlfriend having a casual conversation with her boyfriend, at college campus"
    decoded_text = greedy_match(text, abbreviations)

    words = decoded_text.split()

    word_count = len(words) #left off here123

    if word_count < 2:
        sentence = sentence + decoded_text
        # sentence = sentence + words
        emotion = emotion + "Neutral"
        print(sentence)
        print(emotion)
        return [sentence, emotion]
    else:
        prompt1 = f"""Convert this text and context into a single natural English sentence. 
                    Do not add any extra modifications besides grammar. Don't elaborate.
                    Put just the answer and not the thinking or background information.
                    Do NOT narrate. Do NOT use third-person, do not use second person ("he/she/they said").
                    Keep it casual, first-person, like a couple talking.
                    If you are given a few words and questions, don't just choose one and remove the others. Include all that is inputed.
                    If you receive only 1 word, do not add or remove anything. Just output that word.

        Context: {context}
        Text: "{decoded_text}"

        Respond in just the sentence."""

        response1 = ollama.generate(
            model="gemma3",
            system="Do not change the sentence besides grammar corrections. Do not narrate.",
            prompt=prompt1,
            options={"temperature": 0.1, "num_predict": 30}
        )

        sentence = sentence + response1['response']

        prompt2 = f""" What is the closest emotion invoked from this text? Pick ONLY one that is closest from the Emotions list.

        Context: {context}
        Emotions: {emotionList}
        Text: "{response1['response']}"
                    """
        print(response1['response'])
        response2 = ollama.generate(
            model="gemma3",
            system="Only give 1 word response.",
            prompt=prompt2,
            options={"temperature": 0.1, "num_predict": 20}
        )
        print(response2['response'])

       # emotion = emotion + response2['response']

        results["Emotion"] = emotion
        results["Sentence"] = sentence

        print(sentence)
        print(emotion)

        return1 = [sentence, emotion]
        return results